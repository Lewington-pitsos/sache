- log to wandb
- aux loss to make sure experts are used equally
- dead latents are way too high
- prevent certain experts from dominating the others (currently 3 are being chosen most of the time)
- every batch I'm shuffling

# Anthropic June Update
- TopK (and gated) SAE's do indeed seem to be a pareto improvement over L1 saes

# Anthropic July Update
- it seems that for many concepts a features alone is not enough to pick them out all of the time. You may need multiple features firing together, which may by themselves be uninterpretable.
- when we talk about "linear representation theory" the most important aspect is that features inside neural networks (which probably consist of multiple neurons) be subject to the genreal mathematical idea of linearity, in particular that they can be "scaled" and "added" to one another in a way that is meaningful. E.g. the classic king + woman = queen 